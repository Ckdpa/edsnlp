{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import random\n",
    "\n",
    "import spacy\n",
    "from edsnlp.pipelines.misc.external_model import ModelWrapper\n",
    "\n",
    "from typing import List, Dict, Any"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Defining a model\n",
    "\n",
    "This model can be anything (PyTorch, SKLearn, etc.).  \n",
    "Let's make an extremely basic sentiment analysis model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "class SentimentAnalysisModel:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def batching(\n",
    "        self,\n",
    "        data: Dict[str, List[Any]],\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        i = 0\n",
    "        n = len(data[\"text\"])\n",
    "        while i < n:\n",
    "            yield {k: v[i : i + batch_size] for k, v in data.items()}\n",
    "            i += batch_size\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        batch,\n",
    "    ):\n",
    "        return [\n",
    "            {\n",
    "                \"good\": \"good\" in txt,\n",
    "                \"bad\": \"bad\" in txt,\n",
    "                \"neutral\": \"neutral\" in txt,\n",
    "            }\n",
    "            for txt in batch[\"text\"]\n",
    "        ]\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        data: Dict[str, List[Any]],\n",
    "        batch_size: int,\n",
    "    ):\n",
    "        preds = []\n",
    "        for batch in self.batching(data, batch_size):\n",
    "            preds += self.forward(batch)\n",
    "        return preds\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will test our model with some toy data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "good_texts = [\n",
    "    \"It was a very good movie !\",\n",
    "    \"The cheese was pretty good.\",\n",
    "    \"It's gonna be a very good year. Very good!\",\n",
    "]\n",
    "\n",
    "bad_texts = [\n",
    "    \"I have a bad feeling about this\",\n",
    "    \"This was pretty bad.\"\n",
    "]\n",
    "\n",
    "neutral = [\n",
    "    \"This is a neutral statement.\"\n",
    "]\n",
    "\n",
    "texts = 50*good_texts + 40*bad_texts + 30*neutral\n",
    "\n",
    "random.shuffle(texts)\n",
    "\n",
    "data = dict(text = texts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = SentimentAnalysisModel()\n",
    "preds_from_model = model.predict(data, batch_size = 16)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "preds_from_model[0], data[\"text\"][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "({'good': False, 'bad': False, 'neutral': True},\n",
       " 'This is a neutral statement.')"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Wrap the model\n",
    "\n",
    "To use this model with EDS-NLP, you should wrap in by using the dedicated `ModelWrapper` class.  \n",
    "Two parameters are available here:\n",
    "- `span_getter`: To tell the wrapper how to generate inference data for your Model starting from a spaCy document\n",
    "- `annotation_setter`: From the output predictions of your model, how do you set them on the starting spaCy Doc, Span or Token.\n",
    "\n",
    "When creating your wrapper that inherits from `ModelWrapper`, you can either\n",
    "- Use a pre-registered function for those two parameters\n",
    "- Use your own by re-defining `self.span_getter` or `self.annotation_setter`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "DEFAULT_SPAN_GETTER = {\n",
    "    \"@span_getters\": \"sentences\",\n",
    "}\n",
    "\n",
    "DEFAULT_ANNOTATION_SETTER = {\n",
    "    \"@annotation_setters\": \"from-mapping\",\n",
    "    \"mapping\": {\n",
    "        \"good\": \"_.good\",\n",
    "        \"bad\": \"_.bad\",\n",
    "        \"neutral\": \"_.neutral\",\n",
    "    }\n",
    "}\n",
    "\n",
    "class SentimentAnalysisWrapper(ModelWrapper):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: SentimentAnalysisModel,\n",
    "        span_getter = DEFAULT_SPAN_GETTER,\n",
    "        annotation_setter = DEFAULT_ANNOTATION_SETTER,\n",
    "    ):\n",
    "        super().__init__(model, span_getter, annotation_setter)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "wrap = SentimentAnalysisWrapper(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally we will save this wrapper model:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "wrap.to_pickle(\"./model.pkl\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Use the wrapped model in a pipe\n",
    "\n",
    "Use the `eds.external-model` pipe and give the pickled model path in the configuration"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "nlp = spacy.blank(\"eds\")\n",
    "\n",
    "nlp.add_pipe(\"eds.sentences\")\n",
    "nlp.add_pipe(\"eds.external-model\", config=dict(model=\"./model.pkl\"))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<edsnlp.pipelines.misc.external_model.external_model.ExternalModel at 0x7fe4fa313650>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now simply use `nlp.pipe`:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "spacy_preds = list(nlp.pipe(texts))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 4. Sanity check\n",
    "\n",
    "Let us check that the ouput if the model and the output of `nlp.pipe` matches up:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "spacy_preds = [\n",
    "    dict(\n",
    "        good = doc[0].sent._.good,\n",
    "        bad = doc[0].sent._.bad,\n",
    "        neutral = doc[0].sent._.neutral,\n",
    "    ) for doc in spacy_preds\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "preds_from_model == spacy_preds"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "382c60e41ce00a190f65d8f45615d14db0ccd1b0d25cbfcd143362faf11902d6"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('venv': venv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
